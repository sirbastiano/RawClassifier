{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl \n",
    "import pandas as pd  \n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import math\n",
    "from flops_counter import get_model_complexity_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_lite_params = {\n",
    "    # width_coefficient, depth_coefficient, image_size, dropout_rate\n",
    "    'efficientnet_lite0': [1.0, 1.0, 224, 0.2],\n",
    "    'efficientnet_lite1': [1.0, 1.1, 240, 0.2],\n",
    "    'efficientnet_lite2': [1.1, 1.2, 260, 0.3],\n",
    "    'efficientnet_lite3': [1.2, 1.4, 280, 0.3],\n",
    "    'efficientnet_lite4': [1.4, 1.8, 300, 0.3],\n",
    "}\n",
    "\n",
    "\n",
    "def round_filters(filters, multiplier, divisor=8, min_width=None):\n",
    "    \"\"\"Calculate and round number of filters based on width multiplier.\"\"\"\n",
    "    if not multiplier:\n",
    "        return filters\n",
    "    filters *= multiplier\n",
    "    min_width = min_width or divisor\n",
    "    new_filters = max(min_width, int(filters + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "def round_repeats(repeats, multiplier):\n",
    "    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "    if not multiplier:\n",
    "        return repeats\n",
    "    return int(math.ceil(multiplier * repeats))\n",
    "\n",
    "def drop_connect(x, drop_connect_rate, training):\n",
    "    if not training:\n",
    "        return x\n",
    "    keep_prob = 1.0 - drop_connect_rate\n",
    "    batch_size = x.shape[0]\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=x.dtype, device=x.device)\n",
    "    binary_mask = torch.floor(random_tensor)\n",
    "    x = (x / keep_prob) * binary_mask\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    def __init__(self, inp, final_oup, k, s, expand_ratio, se_ratio, has_se=False):\n",
    "        super(MBConvBlock, self).__init__()\n",
    "\n",
    "        self._momentum = 0.01\n",
    "        self._epsilon = 1e-3\n",
    "        self.input_filters = inp\n",
    "        self.output_filters = final_oup\n",
    "        self.stride = s\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.has_se = has_se\n",
    "        self.id_skip = True  # skip connection and drop connect\n",
    "\n",
    "        # Expansion phase\n",
    "        oup = inp * expand_ratio  # number of output channels\n",
    "        if expand_ratio != 1:\n",
    "            self._expand_conv = nn.Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._momentum, eps=self._epsilon)\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        self._depthwise_conv = nn.Conv2d(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n",
    "            kernel_size=k, padding=(k - 1) // 2, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._momentum, eps=self._epsilon)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1, int(inp * se_ratio))\n",
    "            self._se_reduce = nn.Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = nn.Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Output phase\n",
    "        self._project_conv = nn.Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._momentum, eps=self._epsilon)\n",
    "        self._relu = nn.ReLU6(inplace=True)\n",
    "\n",
    "    def forward(self, x, drop_connect_rate=None):\n",
    "        \"\"\"\n",
    "        :param x: input tensor\n",
    "        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n",
    "        :return: output of block\n",
    "        \"\"\"\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        identity = x\n",
    "        if self.expand_ratio != 1:\n",
    "            x = self._relu(self._bn0(self._expand_conv(x)))\n",
    "        x = self._relu(self._bn1(self._depthwise_conv(x)))\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_expand(self._relu(self._se_reduce(x_squeezed)))\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "\n",
    "        x = self._bn2(self._project_conv(x))\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        if self.id_skip and self.stride == 1  and self.input_filters == self.output_filters:\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, drop_connect_rate, training=self.training)\n",
    "            x += identity  # skip connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class EfficientNetLite(nn.Module):\n",
    "    def __init__(self, widthi_multiplier, depth_multiplier, num_classes, drop_connect_rate, dropout_rate):\n",
    "        super(EfficientNetLite, self).__init__()\n",
    "\n",
    "        # Batch norm parameters\n",
    "        momentum = 0.01\n",
    "        epsilon = 1e-3\n",
    "        self.drop_connect_rate = drop_connect_rate\n",
    "\n",
    "        mb_block_settings = [\n",
    "            #repeat|kernal_size|stride|expand|input|output|se_ratio\n",
    "                [1, 3, 1, 1, 32,  16,  0.25],\n",
    "                [2, 3, 2, 6, 16,  24,  0.25],\n",
    "                [2, 5, 2, 6, 24,  40,  0.25],\n",
    "                [3, 3, 2, 6, 40,  80,  0.25],\n",
    "                [3, 5, 1, 6, 80,  112, 0.25],\n",
    "                [4, 5, 2, 6, 112, 192, 0.25],\n",
    "                [1, 3, 1, 6, 192, 320, 0.25]\n",
    "            ]\n",
    "\n",
    "        # Stem\n",
    "        out_channels = 32\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, out_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=out_channels, momentum=momentum, eps=epsilon),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Build blocks\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for i, stage_setting in enumerate(mb_block_settings):\n",
    "            stage = nn.ModuleList([])\n",
    "            num_repeat, kernal_size, stride, expand_ratio, input_filters, output_filters, se_ratio = stage_setting\n",
    "            # Update block input and output filters based on width multiplier.\n",
    "            input_filters = input_filters if i == 0 else round_filters(input_filters, widthi_multiplier)\n",
    "            output_filters = round_filters(output_filters, widthi_multiplier)\n",
    "            num_repeat= num_repeat if i == 0 or i == len(mb_block_settings) - 1  else round_repeats(num_repeat, depth_multiplier)\n",
    "            \n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            stage.append(MBConvBlock(input_filters, output_filters, kernal_size, stride, expand_ratio, se_ratio, has_se=False))\n",
    "            if num_repeat > 1:\n",
    "                input_filters = output_filters\n",
    "                stride = 1\n",
    "            for _ in range(num_repeat - 1):\n",
    "                stage.append(MBConvBlock(input_filters, output_filters, kernal_size, stride, expand_ratio, se_ratio, has_se=False))\n",
    "            \n",
    "            self.blocks.append(stage)\n",
    "\n",
    "        # Head\n",
    "        in_channels = round_filters(mb_block_settings[-1][5], widthi_multiplier)\n",
    "        out_channels = 1280\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=out_channels, momentum=momentum, eps=epsilon),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        if dropout_rate > 0:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.fc = torch.nn.Linear(out_channels, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        idx = 0\n",
    "        for stage in self.blocks:\n",
    "            for block in stage:\n",
    "                drop_connect_rate = self.drop_connect_rate\n",
    "                if drop_connect_rate:\n",
    "                    drop_connect_rate *= float(idx) / len(self.blocks)\n",
    "                x = block(x, drop_connect_rate)\n",
    "                idx +=1\n",
    "        x = self.head(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 1.0/float(n))\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "    def load_pretrain(self, path):\n",
    "        state_dict = torch.load(path)\n",
    "        self.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "\n",
    "def build_efficientnet_lite(name, num_classes):\n",
    "    width_coefficient, depth_coefficient, _, dropout_rate = efficientnet_lite_params[name]\n",
    "    model = EfficientNetLite(width_coefficient, depth_coefficient, num_classes, 0.2, dropout_rate)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetLite(\n",
      "  4.652 M, 100.000% Params, 0.405 GFLOPs, 100.000% FLOPs, \n",
      "  (stem): Sequential(\n",
      "    0.001 M, 0.020% Params, 0.012 GFLOPs, 2.974% FLOPs, \n",
      "    (0): Conv2d(0.001 M, 0.019% Params, 0.011 GFLOPs, 2.677% FLOPs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.198% FLOPs, 32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.099% FLOPs, inplace=True)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        0.001 M, 0.019% Params, 0.012 GFLOPs, 2.875% FLOPs, \n",
      "        (_depthwise_conv): Conv2d(0.0 M, 0.006% Params, 0.004 GFLOPs, 0.892% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.198% FLOPs, 32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.001 M, 0.011% Params, 0.006 GFLOPs, 1.586% FLOPs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.099% FLOPs, 16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.099% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        0.005 M, 0.110% Params, 0.034 GFLOPs, 8.365% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.002 M, 0.033% Params, 0.019 GFLOPs, 4.759% FLOPs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.0 M, 0.004% Params, 0.002 GFLOPs, 0.595% FLOPs, 96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.001 M, 0.019% Params, 0.003 GFLOPs, 0.669% FLOPs, 96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.0 M, 0.004% Params, 0.001 GFLOPs, 0.149% FLOPs, 96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.002 M, 0.050% Params, 0.007 GFLOPs, 1.785% FLOPs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.037% FLOPs, 24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.372% FLOPs, inplace=True)\n",
      "      )\n",
      "      (1): MBConvBlock(\n",
      "        0.009 M, 0.190% Params, 0.029 GFLOPs, 7.064% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.003 M, 0.074% Params, 0.011 GFLOPs, 2.677% FLOPs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GFLOPs, 0.223% FLOPs, 144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.001 M, 0.028% Params, 0.004 GFLOPs, 1.004% FLOPs, 144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GFLOPs, 0.223% FLOPs, 144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.003 M, 0.074% Params, 0.011 GFLOPs, 2.677% FLOPs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.037% FLOPs, 24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.223% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        0.013 M, 0.290% Params, 0.02 GFLOPs, 4.923% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.003 M, 0.074% Params, 0.011 GFLOPs, 2.677% FLOPs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GFLOPs, 0.223% FLOPs, 144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.004 M, 0.077% Params, 0.003 GFLOPs, 0.697% FLOPs, 144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GFLOPs, 0.056% FLOPs, 144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.006 M, 0.124% Params, 0.005 GFLOPs, 1.115% FLOPs, 144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GFLOPs, 0.015% FLOPs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.139% FLOPs, inplace=True)\n",
      "      )\n",
      "      (1): MBConvBlock(\n",
      "        0.026 M, 0.564% Params, 0.021 GFLOPs, 5.174% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.01 M, 0.206% Params, 0.008 GFLOPs, 1.859% FLOPs, 40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.0 M, 0.010% Params, 0.0 GFLOPs, 0.093% FLOPs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.006 M, 0.129% Params, 0.005 GFLOPs, 1.162% FLOPs, 240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.0 M, 0.010% Params, 0.0 GFLOPs, 0.093% FLOPs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.01 M, 0.206% Params, 0.008 GFLOPs, 1.859% FLOPs, 240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GFLOPs, 0.015% FLOPs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.093% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        0.032 M, 0.690% Params, 0.012 GFLOPs, 3.075% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.01 M, 0.206% Params, 0.008 GFLOPs, 1.859% FLOPs, 40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.0 M, 0.010% Params, 0.0 GFLOPs, 0.093% FLOPs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.002 M, 0.046% Params, 0.0 GFLOPs, 0.105% FLOPs, 240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.0 M, 0.010% Params, 0.0 GFLOPs, 0.023% FLOPs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.019 M, 0.413% Params, 0.004 GFLOPs, 0.929% FLOPs, 240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GFLOPs, 0.008% FLOPs, 80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.058% FLOPs, inplace=True)\n",
      "      )\n",
      "      (1-2): 2 x MBConvBlock(\n",
      "        0.083 M, 1.788% Params, 0.016 GFLOPs, 4.074% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.038 M, 0.825% Params, 0.008 GFLOPs, 1.859% FLOPs, 80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.001 M, 0.021% Params, 0.0 GFLOPs, 0.046% FLOPs, 480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.004 M, 0.093% Params, 0.001 GFLOPs, 0.209% FLOPs, 480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.001 M, 0.021% Params, 0.0 GFLOPs, 0.046% FLOPs, 480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.038 M, 0.825% Params, 0.008 GFLOPs, 1.859% FLOPs, 480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GFLOPs, 0.008% FLOPs, 80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.046% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        0.106 M, 2.285% Params, 0.021 GFLOPs, 5.193% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.038 M, 0.825% Params, 0.008 GFLOPs, 1.859% FLOPs, 80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.001 M, 0.021% Params, 0.0 GFLOPs, 0.046% FLOPs, 480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.012 M, 0.258% Params, 0.002 GFLOPs, 0.581% FLOPs, 480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.001 M, 0.021% Params, 0.0 GFLOPs, 0.046% FLOPs, 480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.054 M, 1.156% Params, 0.011 GFLOPs, 2.602% FLOPs, 480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.005% Params, 0.0 GFLOPs, 0.011% FLOPs, 112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.046% FLOPs, inplace=True)\n",
      "      )\n",
      "      (1-2): 2 x MBConvBlock(\n",
      "        0.17 M, 3.659% Params, 0.034 GFLOPs, 8.306% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.075 M, 1.618% Params, 0.015 GFLOPs, 3.643% FLOPs, 112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.001 M, 0.029% Params, 0.0 GFLOPs, 0.065% FLOPs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.017 M, 0.361% Params, 0.003 GFLOPs, 0.813% FLOPs, 672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.001 M, 0.029% Params, 0.0 GFLOPs, 0.065% FLOPs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.075 M, 1.618% Params, 0.015 GFLOPs, 3.643% FLOPs, 672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.005% Params, 0.0 GFLOPs, 0.011% FLOPs, 112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.065% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        0.224 M, 4.819% Params, 0.022 GFLOPs, 5.535% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.075 M, 1.618% Params, 0.015 GFLOPs, 3.643% FLOPs, 112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.001 M, 0.029% Params, 0.0 GFLOPs, 0.065% FLOPs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.017 M, 0.361% Params, 0.001 GFLOPs, 0.203% FLOPs, 672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.001 M, 0.029% Params, 0.0 GFLOPs, 0.016% FLOPs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.129 M, 2.774% Params, 0.006 GFLOPs, 1.561% FLOPs, 672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.008% Params, 0.0 GFLOPs, 0.005% FLOPs, 192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.041% FLOPs, inplace=True)\n",
      "      )\n",
      "      (1-3): 3 x MBConvBlock(\n",
      "        0.476 M, 10.236% Params, 0.023 GFLOPs, 5.790% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.221 M, 4.755% Params, 0.011 GFLOPs, 2.677% FLOPs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.002 M, 0.050% Params, 0.0 GFLOPs, 0.028% FLOPs, 1152, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.029 M, 0.619% Params, 0.001 GFLOPs, 0.349% FLOPs, 1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.002 M, 0.050% Params, 0.0 GFLOPs, 0.028% FLOPs, 1152, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.221 M, 4.755% Params, 0.011 GFLOPs, 2.677% FLOPs, 1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.0 M, 0.008% Params, 0.0 GFLOPs, 0.005% FLOPs, 192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.028% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        0.605 M, 13.015% Params, 0.03 GFLOPs, 7.355% FLOPs, \n",
      "        (_expand_conv): Conv2d(0.221 M, 4.755% Params, 0.011 GFLOPs, 2.677% FLOPs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn0): BatchNorm2d(0.002 M, 0.050% Params, 0.0 GFLOPs, 0.028% FLOPs, 1152, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2d(0.01 M, 0.223% Params, 0.001 GFLOPs, 0.125% FLOPs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (_bn1): BatchNorm2d(0.002 M, 0.050% Params, 0.0 GFLOPs, 0.028% FLOPs, 1152, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_project_conv): Conv2d(0.369 M, 7.924% Params, 0.018 GFLOPs, 4.461% FLOPs, 1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_bn2): BatchNorm2d(0.001 M, 0.014% Params, 0.0 GFLOPs, 0.008% FLOPs, 320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (_relu): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.028% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    0.412 M, 8.860% Params, 0.02 GFLOPs, 5.004% FLOPs, \n",
      "    (0): Conv2d(0.41 M, 8.805% Params, 0.02 GFLOPs, 4.957% FLOPs, 320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(0.003 M, 0.055% Params, 0.0 GFLOPs, 0.031% FLOPs, 1280, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.015% FLOPs, inplace=True)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.015% FLOPs, output_size=(1, 1))\n",
      "  (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.2, inplace=False)\n",
      "  (fc): Linear(1.281 M, 27.536% Params, 0.001 GFLOPs, 0.316% FLOPs, in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "==============================\n",
      "Input shape: (3, 224, 224)\n",
      "Flops: 0.4 GFLOPs\n",
      "Params: 4.65 M\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "model_name = 'efficientnet_lite0'\n",
    "model = build_efficientnet_lite(model_name, 1000)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "wh = efficientnet_lite_params[model_name][2]\n",
    "input_shape = (3, wh, wh)\n",
    "flops, params = get_model_complexity_info(model, input_shape)\n",
    "split_line = '=' * 30\n",
    "print(f'{split_line}\\nInput shape: {input_shape}\\n'\n",
    "        f'Flops: {flops}\\nParams: {params}\\n{split_line}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
